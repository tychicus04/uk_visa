{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ffecb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-02 15:14:10,761 - INFO - Database schema created successfully\n",
      "2025-08-02 15:14:10,762 - INFO - Starting to crawl all tests...\n",
      "2025-08-02 15:14:10,763 - INFO - === Crawling Chapter-based Tests ===\n",
      "2025-08-02 15:14:10,764 - INFO - Processing chapter_1\n",
      "2025-08-02 15:14:10,764 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-1-2 (Chapter: chapter_1, Type: chapter)\n",
      "2025-08-02 15:14:13,268 - INFO - Extracted 24 questions from test-1-2\n",
      "2025-08-02 15:14:15,273 - INFO - Processing chapter_2\n",
      "2025-08-02 15:14:15,274 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-1-2 (Chapter: chapter_2, Type: chapter)\n",
      "2025-08-02 15:14:16,255 - INFO - Extracted 24 questions from test-1-2\n",
      "2025-08-02 15:14:18,258 - INFO - Processing chapter_3\n",
      "2025-08-02 15:14:18,259 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-3-1 (Chapter: chapter_3, Type: chapter)\n",
      "2025-08-02 15:14:19,548 - INFO - Extracted 24 questions from test-3-1\n",
      "2025-08-02 15:14:21,553 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-3-2 (Chapter: chapter_3, Type: chapter)\n",
      "2025-08-02 15:14:23,020 - INFO - Extracted 24 questions from test-3-2\n",
      "2025-08-02 15:14:25,025 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-3-3 (Chapter: chapter_3, Type: chapter)\n",
      "2025-08-02 15:14:26,186 - INFO - Extracted 24 questions from test-3-3\n",
      "2025-08-02 15:14:28,190 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-3-4 (Chapter: chapter_3, Type: chapter)\n",
      "2025-08-02 15:14:29,393 - INFO - Extracted 24 questions from test-3-4\n",
      "2025-08-02 15:14:31,398 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-3-5 (Chapter: chapter_3, Type: chapter)\n",
      "2025-08-02 15:14:33,004 - INFO - Extracted 24 questions from test-3-5\n",
      "2025-08-02 15:14:35,009 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-3-6 (Chapter: chapter_3, Type: chapter)\n",
      "2025-08-02 15:14:36,456 - INFO - Extracted 24 questions from test-3-6\n",
      "2025-08-02 15:14:38,459 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-3-7 (Chapter: chapter_3, Type: chapter)\n",
      "2025-08-02 15:14:40,007 - INFO - Extracted 24 questions from test-3-7\n",
      "2025-08-02 15:14:42,011 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-3-8 (Chapter: chapter_3, Type: chapter)\n",
      "2025-08-02 15:14:44,050 - INFO - Extracted 24 questions from test-3-8\n",
      "2025-08-02 15:14:46,051 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-3-9 (Chapter: chapter_3, Type: chapter)\n",
      "2025-08-02 15:14:47,442 - INFO - Extracted 24 questions from test-3-9\n",
      "2025-08-02 15:14:49,447 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-3-10 (Chapter: chapter_3, Type: chapter)\n",
      "2025-08-02 15:14:51,064 - INFO - Extracted 24 questions from test-3-10\n",
      "2025-08-02 15:14:53,065 - INFO - Processing chapter_4\n",
      "2025-08-02 15:14:53,065 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-4-1 (Chapter: chapter_4, Type: chapter)\n",
      "2025-08-02 15:14:54,470 - INFO - Extracted 24 questions from test-4-1\n",
      "2025-08-02 15:14:56,474 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-4-2 (Chapter: chapter_4, Type: chapter)\n",
      "2025-08-02 15:14:57,977 - INFO - Extracted 24 questions from test-4-2\n",
      "2025-08-02 15:14:59,979 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-4-3 (Chapter: chapter_4, Type: chapter)\n",
      "2025-08-02 15:15:01,290 - INFO - Extracted 24 questions from test-4-3\n",
      "2025-08-02 15:15:03,291 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-4-4 (Chapter: chapter_4, Type: chapter)\n",
      "2025-08-02 15:15:05,040 - INFO - Extracted 24 questions from test-4-4\n",
      "2025-08-02 15:15:07,044 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-4-5 (Chapter: chapter_4, Type: chapter)\n",
      "2025-08-02 15:15:08,516 - INFO - Extracted 24 questions from test-4-5\n",
      "2025-08-02 15:15:10,521 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-4-6 (Chapter: chapter_4, Type: chapter)\n",
      "2025-08-02 15:15:11,746 - INFO - Extracted 24 questions from test-4-6\n",
      "2025-08-02 15:15:13,747 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-4-7 (Chapter: chapter_4, Type: chapter)\n",
      "2025-08-02 15:15:15,053 - INFO - Extracted 24 questions from test-4-7\n",
      "2025-08-02 15:15:17,057 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-4-8 (Chapter: chapter_4, Type: chapter)\n",
      "2025-08-02 15:15:18,144 - INFO - Extracted 24 questions from test-4-8\n",
      "2025-08-02 15:15:20,148 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-4-9 (Chapter: chapter_4, Type: chapter)\n",
      "2025-08-02 15:15:21,289 - INFO - Extracted 24 questions from test-4-9\n",
      "2025-08-02 15:15:23,294 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-4-10 (Chapter: chapter_4, Type: chapter)\n",
      "2025-08-02 15:15:24,485 - INFO - Extracted 24 questions from test-4-10\n",
      "2025-08-02 15:15:26,490 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-4-11 (Chapter: chapter_4, Type: chapter)\n",
      "2025-08-02 15:15:27,688 - INFO - Extracted 24 questions from test-4-11\n",
      "2025-08-02 15:15:29,691 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-4-12 (Chapter: chapter_4, Type: chapter)\n",
      "2025-08-02 15:15:32,588 - INFO - Extracted 24 questions from test-4-12\n",
      "2025-08-02 15:15:34,590 - INFO - Processing chapter_5\n",
      "2025-08-02 15:15:34,592 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-5-1 (Chapter: chapter_5, Type: chapter)\n",
      "2025-08-02 15:15:36,444 - INFO - Extracted 24 questions from test-5-1\n",
      "2025-08-02 15:15:38,448 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-5-2 (Chapter: chapter_5, Type: chapter)\n",
      "2025-08-02 15:15:39,882 - INFO - Extracted 24 questions from test-5-2\n",
      "2025-08-02 15:15:41,885 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-5-3 (Chapter: chapter_5, Type: chapter)\n",
      "2025-08-02 15:15:43,309 - INFO - Extracted 24 questions from test-5-3\n",
      "2025-08-02 15:15:45,315 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-5-4 (Chapter: chapter_5, Type: chapter)\n",
      "2025-08-02 15:15:46,978 - INFO - Extracted 24 questions from test-5-4\n",
      "2025-08-02 15:15:48,983 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-5-5 (Chapter: chapter_5, Type: chapter)\n",
      "2025-08-02 15:15:50,089 - INFO - Extracted 24 questions from test-5-5\n",
      "2025-08-02 15:15:52,093 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-5-6 (Chapter: chapter_5, Type: chapter)\n",
      "2025-08-02 15:15:53,240 - INFO - Extracted 24 questions from test-5-6\n",
      "2025-08-02 15:15:55,242 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-5-7 (Chapter: chapter_5, Type: chapter)\n",
      "2025-08-02 15:15:56,242 - INFO - Extracted 24 questions from test-5-7\n",
      "2025-08-02 15:15:58,243 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-5-8 (Chapter: chapter_5, Type: chapter)\n",
      "2025-08-02 15:16:00,244 - INFO - Extracted 24 questions from test-5-8\n",
      "2025-08-02 15:16:02,247 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-5-9 (Chapter: chapter_5, Type: chapter)\n",
      "2025-08-02 15:16:04,513 - INFO - Extracted 24 questions from test-5-9\n",
      "2025-08-02 15:16:06,515 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-5-10 (Chapter: chapter_5, Type: chapter)\n",
      "2025-08-02 15:16:08,530 - INFO - Extracted 24 questions from test-5-10\n",
      "2025-08-02 15:16:10,531 - INFO - === Crawling Comprehensive Tests ===\n",
      "2025-08-02 15:16:10,532 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-1 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:16:11,628 - INFO - Extracted 24 questions from test-1\n",
      "2025-08-02 15:16:13,631 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-2 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:16:16,993 - INFO - Extracted 24 questions from test-2\n",
      "2025-08-02 15:16:18,996 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-3 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:16:21,140 - INFO - Extracted 24 questions from test-3\n",
      "2025-08-02 15:16:23,141 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-4 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:16:24,429 - INFO - Extracted 24 questions from test-4\n",
      "2025-08-02 15:16:26,430 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-5 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:16:27,440 - INFO - Extracted 24 questions from test-5\n",
      "2025-08-02 15:16:29,443 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-6 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:16:30,494 - INFO - Extracted 24 questions from test-6\n",
      "2025-08-02 15:16:32,494 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-7 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:16:33,622 - INFO - Extracted 24 questions from test-7\n",
      "2025-08-02 15:16:35,623 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-8 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:16:36,917 - INFO - Extracted 24 questions from test-8\n",
      "2025-08-02 15:16:38,922 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-9 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:16:40,279 - INFO - Extracted 24 questions from test-9\n",
      "2025-08-02 15:16:42,280 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-10 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:16:43,446 - INFO - Extracted 24 questions from test-10\n",
      "2025-08-02 15:16:45,449 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-11 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:16:46,443 - INFO - Extracted 24 questions from test-11\n",
      "2025-08-02 15:16:48,447 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-12 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:16:49,707 - INFO - Extracted 24 questions from test-12\n",
      "2025-08-02 15:16:51,710 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-13 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:16:52,704 - INFO - Extracted 24 questions from test-13\n",
      "2025-08-02 15:16:54,705 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-14 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:16:55,896 - INFO - Extracted 24 questions from test-14\n",
      "2025-08-02 15:16:57,902 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-15 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:16:59,283 - INFO - Extracted 24 questions from test-15\n",
      "2025-08-02 15:17:01,286 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-16 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:17:02,616 - INFO - Extracted 24 questions from test-16\n",
      "2025-08-02 15:17:04,622 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-17 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:17:05,693 - INFO - Extracted 24 questions from test-17\n",
      "2025-08-02 15:17:07,694 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-18 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:17:08,855 - INFO - Extracted 24 questions from test-18\n",
      "2025-08-02 15:17:10,860 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-19 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:17:12,036 - INFO - Extracted 24 questions from test-19\n",
      "2025-08-02 15:17:14,039 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-20 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:17:15,300 - INFO - Extracted 24 questions from test-20\n",
      "2025-08-02 15:17:17,304 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-21 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:17:18,583 - INFO - Extracted 24 questions from test-21\n",
      "2025-08-02 15:17:20,588 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-22 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:17:21,762 - INFO - Extracted 24 questions from test-22\n",
      "2025-08-02 15:17:23,763 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-23 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:17:25,136 - INFO - Extracted 24 questions from test-23\n",
      "2025-08-02 15:17:27,138 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-24 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:17:28,234 - INFO - Extracted 24 questions from test-24\n",
      "2025-08-02 15:17:30,238 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-25 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:17:31,477 - INFO - Extracted 24 questions from test-25\n",
      "2025-08-02 15:17:33,481 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-26 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:17:34,607 - INFO - Extracted 24 questions from test-26\n",
      "2025-08-02 15:17:36,611 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-27 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:17:37,632 - INFO - Extracted 24 questions from test-27\n",
      "2025-08-02 15:17:39,636 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-28 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:17:40,708 - INFO - Extracted 24 questions from test-28\n",
      "2025-08-02 15:17:42,713 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-29 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:17:44,001 - INFO - Extracted 24 questions from test-29\n",
      "2025-08-02 15:17:46,006 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-30 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:17:47,217 - INFO - Extracted 24 questions from test-30\n",
      "2025-08-02 15:17:49,221 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-31 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:17:50,492 - INFO - Extracted 24 questions from test-31\n",
      "2025-08-02 15:17:52,494 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-32 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:17:53,663 - INFO - Extracted 24 questions from test-32\n",
      "2025-08-02 15:17:55,667 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-33 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:17:56,710 - INFO - Extracted 24 questions from test-33\n",
      "2025-08-02 15:17:58,713 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-34 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:17:59,956 - INFO - Extracted 24 questions from test-34\n",
      "2025-08-02 15:18:01,961 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-35 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:18:03,139 - INFO - Extracted 24 questions from test-35\n",
      "2025-08-02 15:18:05,141 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-36 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:18:06,226 - INFO - Extracted 24 questions from test-36\n",
      "2025-08-02 15:18:08,229 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-37 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:18:09,695 - INFO - Extracted 24 questions from test-37\n",
      "2025-08-02 15:18:11,699 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-38 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:18:12,758 - INFO - Extracted 24 questions from test-38\n",
      "2025-08-02 15:18:14,760 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-39 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:18:15,745 - INFO - Extracted 24 questions from test-39\n",
      "2025-08-02 15:18:17,748 - INFO - Crawling: https://lifeintheuktestweb.co.uk/test-40 (Chapter: None, Type: comprehensive)\n",
      "2025-08-02 15:18:18,902 - INFO - Extracted 24 questions from test-40\n",
      "2025-08-02 15:18:20,907 - INFO - Crawling completed. Total questions: 1776\n",
      "2025-08-02 15:18:20,997 - INFO - Data saved to uk_visa_all_questions.json\n",
      "2025-08-02 15:18:22,349 - INFO - Data saved to database successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling completed! Found 1776 questions.\n",
      "Chapter-based questions: 816\n",
      "Comprehensive test questions: 960\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import mysql.connector\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from typing import List, Dict, Optional\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class Answer:\n",
    "    id: str\n",
    "    text: str\n",
    "    is_correct: bool = False\n",
    "\n",
    "@dataclass\n",
    "class Question:\n",
    "    id: str\n",
    "    chapter: Optional[str]\n",
    "    test_number: str\n",
    "    test_type: str  # 'chapter' or 'comprehensive' or 'exam'\n",
    "    question_text: str\n",
    "    question_type: str  # 'radio' or 'checkbox'\n",
    "    answers: List[Answer]\n",
    "    explanation: str\n",
    "    correct_answers: List[str]  # List of correct answer IDs\n",
    "\n",
    "class UKVisaTestCrawler:\n",
    "    def __init__(self, db_config: Optional[Dict] = None):\n",
    "        self.base_url = \"https://lifeintheuktestweb.co.uk\"\n",
    "        self.session = self._create_session()\n",
    "        self.db_config = db_config\n",
    "        self.questions_data = []\n",
    "        \n",
    "        # Test URLs organized by type\n",
    "        self.test_configs = {\n",
    "            # Chapter-based tests\n",
    "            \"chapter_tests\": {\n",
    "                \"chapter_1\": [\n",
    "                    \"test-1-2\"  # Chapters 1 & 2 combined test\n",
    "                ],\n",
    "                \"chapter_2\": [\n",
    "                    \"test-1-2\"  # Same test, but we'll mark it for both chapters\n",
    "                ],\n",
    "                \"chapter_3\": [\n",
    "                    f\"test-3-{i}\" for i in range(1, 11)\n",
    "                ],\n",
    "                \"chapter_4\": [\n",
    "                    f\"test-4-{i}\" for i in range(1, 13)\n",
    "                ],\n",
    "                \"chapter_5\": [\n",
    "                    f\"test-5-{i}\" for i in range(1, 11)\n",
    "                ]\n",
    "            },\n",
    "            # Comprehensive tests (no specific chapter)\n",
    "            \"comprehensive_tests\": [\n",
    "                f\"test-{i}\" for i in range(1, 41)  # test-1 to test-40\n",
    "            ],\n",
    "            # Exam tests (not implemented yet, placeholder)\n",
    "            \"exam_tests\": [\n",
    "                # Placeholder for future exam tests \n",
    "                f\"british-citizenship-test-{i}\" for i in range(1, 16)\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    def _create_session(self):\n",
    "        \"\"\"Create a robust session with retry strategy\"\"\"\n",
    "        session = requests.Session()\n",
    "        \n",
    "        # Retry strategy\n",
    "        retry_strategy = Retry(\n",
    "            total=3,\n",
    "            backoff_factor=1,\n",
    "            status_forcelist=[429, 500, 502, 503, 504],\n",
    "            allowed_methods=[\"GET\"]\n",
    "        )\n",
    "        \n",
    "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "        session.mount(\"http://\", adapter)\n",
    "        session.mount(\"https://\", adapter)\n",
    "        \n",
    "        # Headers to appear more like a regular browser\n",
    "        session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "        })\n",
    "        \n",
    "        return session\n",
    "\n",
    "    def extract_question_data(self, html_content: str, chapter: Optional[str], test_number: str, test_type: str) -> List[Question]:\n",
    "        \"\"\"Extract question data from HTML content\"\"\"\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        questions = []\n",
    "        \n",
    "        # Find all question containers\n",
    "        question_containers = soup.find_all('div', class_='container_question')\n",
    "        \n",
    "        for container in question_containers:\n",
    "            try:\n",
    "                question_id = container.get('data-id_question', '')\n",
    "                \n",
    "                # Extract question text\n",
    "                question_element = container.find('div', class_='question')\n",
    "                if not question_element:\n",
    "                    continue\n",
    "                    \n",
    "                question_text = question_element.get_text(strip=True)\n",
    "                \n",
    "                # Extract answers\n",
    "                answers = []\n",
    "                answer_container = container.find('ul', class_='container_answer')\n",
    "                if not answer_container:\n",
    "                    continue\n",
    "                \n",
    "                answer_items = answer_container.find_all('li')\n",
    "                question_type = 'radio'  # default\n",
    "                \n",
    "                for item in answer_items:\n",
    "                    input_element = item.find('input')\n",
    "                    if not input_element:\n",
    "                        continue\n",
    "                        \n",
    "                    answer_id = input_element.get('data-id_answer', '')\n",
    "                    input_type = input_element.get('type', 'radio')\n",
    "                    if input_type == 'checkbox':\n",
    "                        question_type = 'checkbox'\n",
    "                    \n",
    "                    # Get answer text (remove the input element)\n",
    "                    label = item.find('label')\n",
    "                    if label:\n",
    "                        # Clone the label and remove input to get clean text\n",
    "                        label_copy = BeautifulSoup(str(label), 'html.parser').find('label')\n",
    "                        input_in_label = label_copy.find('input')\n",
    "                        if input_in_label:\n",
    "                            input_in_label.decompose()\n",
    "                        answer_text = label_copy.get_text(strip=True)\n",
    "                    else:\n",
    "                        answer_text = item.get_text(strip=True)\n",
    "                    \n",
    "                    answers.append(Answer(id=answer_id, text=answer_text))\n",
    "                \n",
    "                # Extract explanation and correct answers\n",
    "                explanation = \"\"\n",
    "                correct_answers = []\n",
    "                explanation_container = container.find('div', class_='container_explication')\n",
    "                \n",
    "                if explanation_container:\n",
    "                    explanation = explanation_container.get_text(strip=True)\n",
    "                    \n",
    "                    # Try to identify correct answers from explanation\n",
    "                    # Look for strong tags or specific patterns\n",
    "                    strong_elements = explanation_container.find_all('strong')\n",
    "                    for strong in strong_elements:\n",
    "                        strong_text = strong.get_text(strip=True)\n",
    "                        # Match this text with answers\n",
    "                        for answer in answers:\n",
    "                            if strong_text.lower() in answer.text.lower() or answer.text.lower() in strong_text.lower():\n",
    "                                answer.is_correct = True\n",
    "                                if answer.id not in correct_answers:\n",
    "                                    correct_answers.append(answer.id)\n",
    "                    \n",
    "                    # If no strong tags found, try to parse explanation text\n",
    "                    if not correct_answers:\n",
    "                        correct_answers = self._parse_correct_answers_from_explanation(explanation, answers)\n",
    "                \n",
    "                question = Question(\n",
    "                    id=question_id,\n",
    "                    chapter=chapter,\n",
    "                    test_number=test_number,\n",
    "                    test_type=test_type,\n",
    "                    question_text=question_text,\n",
    "                    question_type=question_type,\n",
    "                    answers=answers,\n",
    "                    explanation=explanation,\n",
    "                    correct_answers=correct_answers\n",
    "                )\n",
    "                \n",
    "                questions.append(question)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error extracting question from container: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return questions\n",
    "\n",
    "    def _parse_correct_answers_from_explanation(self, explanation: str, answers: List[Answer]) -> List[str]:\n",
    "        \"\"\"Try to identify correct answers from explanation text\"\"\"\n",
    "        correct_ids = []\n",
    "        \n",
    "        # Common patterns in explanations\n",
    "        patterns = [\n",
    "            r\"correct answer[s]?[:\\s]*([^.]+)\",\n",
    "            r\"answer[s]?[:\\s]*([^.]+)\\s+is correct\",\n",
    "            r\"([^.]+)\\s+is the correct answer\",\n",
    "            r\"([^.]+)\\s+are the correct answers\",\n",
    "            r\"The correct answers? (?:are?|is) ([^.]+)\"\n",
    "        ]\n",
    "        \n",
    "        explanation_lower = explanation.lower()\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            matches = re.findall(pattern, explanation_lower, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                for answer in answers:\n",
    "                    # More flexible matching\n",
    "                    answer_lower = answer.text.lower()\n",
    "                    match_lower = match.lower()\n",
    "                    \n",
    "                    # Check if answer text is substantially contained in match or vice versa\n",
    "                    if (len(answer_lower) > 10 and answer_lower in match_lower) or \\\n",
    "                       (len(match_lower) > 10 and match_lower in answer_lower) or \\\n",
    "                       (answer_lower == match_lower):\n",
    "                        answer.is_correct = True\n",
    "                        if answer.id not in correct_ids:\n",
    "                            correct_ids.append(answer.id)\n",
    "        \n",
    "        return correct_ids\n",
    "\n",
    "    def crawl_test(self, test_path: str, chapter: Optional[str], test_number: str, test_type: str, retry_count: int = 3) -> List[Question]:\n",
    "        \"\"\"Crawl a single test and return questions with retry mechanism\"\"\"\n",
    "        url = f\"{self.base_url}/{test_path}\"\n",
    "        logger.info(f\"Crawling: {url} (Chapter: {chapter}, Type: {test_type})\")\n",
    "        \n",
    "        for attempt in range(retry_count):\n",
    "            try:\n",
    "                response = self.session.get(url, timeout=15)\n",
    "                response.raise_for_status()\n",
    "                \n",
    "                questions = self.extract_question_data(response.text, chapter, test_number, test_type)\n",
    "                logger.info(f\"Extracted {len(questions)} questions from {test_path}\")\n",
    "                \n",
    "                return questions\n",
    "                \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                logger.warning(f\"Attempt {attempt + 1} failed for {url}: {e}\")\n",
    "                if attempt < retry_count - 1:\n",
    "                    wait_time = (attempt + 1) * 2  # Exponential backoff\n",
    "                    logger.info(f\"Waiting {wait_time} seconds before retry...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    logger.error(f\"Failed to crawl {url} after {retry_count} attempts\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Unexpected error crawling {url}: {e}\")\n",
    "                break\n",
    "        \n",
    "        return []\n",
    "\n",
    "    def crawl_all_tests(self):\n",
    "        \"\"\"Crawl all tests and collect data\"\"\"\n",
    "        logger.info(\"Starting to crawl all tests...\")\n",
    "        \n",
    "        # Crawl chapter-based tests\n",
    "        logger.info(\"=== Crawling Chapter-based Tests ===\")\n",
    "        for chapter, test_paths in self.test_configs[\"chapter_tests\"].items():\n",
    "            logger.info(f\"Processing {chapter}\")\n",
    "            \n",
    "            for test_path in test_paths:\n",
    "                # Extract test number from path\n",
    "                test_number = test_path.split('-')[-1]\n",
    "                \n",
    "                questions = self.crawl_test(test_path, chapter, test_number, \"chapter\")\n",
    "                self.questions_data.extend(questions)\n",
    "                \n",
    "                # Be respectful to the server\n",
    "                time.sleep(2)\n",
    "        \n",
    "        # Crawl comprehensive tests\n",
    "        logger.info(\"=== Crawling Comprehensive Tests ===\")\n",
    "        for test_path in self.test_configs[\"comprehensive_tests\"]:\n",
    "            # Extract test number from path\n",
    "            test_number = test_path.split('-')[-1]\n",
    "            \n",
    "            questions = self.crawl_test(test_path, None, test_number, \"comprehensive\")\n",
    "            self.questions_data.extend(questions)\n",
    "            \n",
    "            # Be respectful to the server\n",
    "            time.sleep(2)\n",
    "\n",
    "        # Crawl exam tests (if implemented in the future)\n",
    "        logger.info(\"=== Crawling Exam Tests (Placeholder) ===\")\n",
    "        for test_path in self.test_configs[\"exam_tests\"]:\n",
    "            # Extract test number from path\n",
    "            test_number = test_path.split('-')[-1]\n",
    "            \n",
    "            questions = self.crawl_test(test_path, None, test_number, \"exam\")\n",
    "            self.questions_data.extend(questions)\n",
    "            \n",
    "            # Be respectful to the server\n",
    "            time.sleep(2)\n",
    "        \n",
    "        logger.info(f\"Crawling completed. Total questions: {len(self.questions_data)}\")\n",
    "\n",
    "    def save_to_json(self, filename: str = \"uk_visa_all_questions.json\"):\n",
    "        \"\"\"Save collected data to JSON file\"\"\"\n",
    "        data = {\n",
    "            \"metadata\": {\n",
    "                \"total_questions\": len(self.questions_data),\n",
    "                \"crawled_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"source\": \"lifeintheuktestweb.co.uk\",\n",
    "                \"test_types\": {\n",
    "                    \"chapter\": len([q for q in self.questions_data if q.test_type == \"chapter\"]),\n",
    "                    \"comprehensive\": len([q for q in self.questions_data if q.test_type == \"comprehensive\"]),\n",
    "                    \"exam\": len([q for q in self.questions_data if q.test_type == \"exam\"])\n",
    "                }\n",
    "            },\n",
    "            \"questions\": []\n",
    "        }\n",
    "        \n",
    "        for question in self.questions_data:\n",
    "            question_dict = {\n",
    "                \"id\": question.id,\n",
    "                \"chapter\": question.chapter,\n",
    "                \"test_number\": question.test_number,\n",
    "                \"test_type\": question.test_type,\n",
    "                \"question_text\": question.question_text,\n",
    "                \"question_type\": question.question_type,\n",
    "                \"answers\": [\n",
    "                    {\n",
    "                        \"id\": answer.id,\n",
    "                        \"text\": answer.text,\n",
    "                        \"is_correct\": answer.is_correct\n",
    "                    }\n",
    "                    for answer in question.answers\n",
    "                ],\n",
    "                \"explanation\": question.explanation,\n",
    "                \"correct_answers\": question.correct_answers\n",
    "            }\n",
    "            data[\"questions\"].append(question_dict)\n",
    "        \n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        logger.info(f\"Data saved to {filename}\")\n",
    "\n",
    "    def create_database_schema(self):\n",
    "        \"\"\"Create MySQL database schema\"\"\"\n",
    "        if not self.db_config:\n",
    "            logger.error(\"Database configuration not provided\")\n",
    "            return\n",
    "        \n",
    "        connection = mysql.connector.connect(**self.db_config)\n",
    "        cursor = connection.cursor()\n",
    "        \n",
    "        # Create tables\n",
    "        schema_sql = \"\"\"\n",
    "        CREATE DATABASE IF NOT EXISTS uk_visa_test CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;\n",
    "        USE uk_visa_test;\n",
    "        \n",
    "        CREATE TABLE IF NOT EXISTS chapters (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            chapter_number INT NOT NULL,\n",
    "            name VARCHAR(100) NOT NULL,\n",
    "            description TEXT,\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            UNIQUE KEY unique_chapter_number (chapter_number)\n",
    "        );\n",
    "        \n",
    "        CREATE TABLE IF NOT EXISTS tests (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            chapter_id INT NULL,\n",
    "            test_number VARCHAR(10) NOT NULL,\n",
    "            test_type ENUM('chapter', 'comprehensive', 'exam') NOT NULL,\n",
    "            title VARCHAR(255),\n",
    "            url VARCHAR(255),\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            FOREIGN KEY (chapter_id) REFERENCES chapters(id) ON DELETE SET NULL,\n",
    "            INDEX idx_test_type (test_type),\n",
    "            INDEX idx_test_number (test_number)\n",
    "        );\n",
    "        \n",
    "        CREATE TABLE IF NOT EXISTS questions (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            test_id INT NOT NULL,\n",
    "            question_id VARCHAR(50) NOT NULL,\n",
    "            question_text TEXT NOT NULL,\n",
    "            question_type ENUM('radio', 'checkbox') NOT NULL,\n",
    "            explanation TEXT,\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            FOREIGN KEY (test_id) REFERENCES tests(id) ON DELETE CASCADE,\n",
    "            INDEX idx_question_id (question_id),\n",
    "            INDEX idx_question_type (question_type)\n",
    "        );\n",
    "        \n",
    "        CREATE TABLE IF NOT EXISTS answers (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            question_id INT NOT NULL,\n",
    "            answer_id VARCHAR(50) NOT NULL,\n",
    "            answer_text TEXT NOT NULL,\n",
    "            is_correct BOOLEAN DEFAULT FALSE,\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            FOREIGN KEY (question_id) REFERENCES questions(id) ON DELETE CASCADE,\n",
    "            INDEX idx_answer_id (answer_id),\n",
    "            INDEX idx_is_correct (is_correct)\n",
    "        );\n",
    "        \"\"\"\n",
    "        \n",
    "        # Execute schema creation\n",
    "        for statement in schema_sql.split(';'):\n",
    "            if statement.strip():\n",
    "                cursor.execute(statement)\n",
    "        \n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        \n",
    "        logger.info(\"Database schema created successfully\")\n",
    "\n",
    "    def _insert_chapters(self, cursor):\n",
    "        \"\"\"Insert chapter data\"\"\"\n",
    "        chapters_data = [\n",
    "            (1, \"Chapter 1: The Values and Principles of the UK\"),\n",
    "            (2, \"Chapter 2: What is the UK?\"),\n",
    "            (3, \"Chapter 3: A Long and Illustrious History\"),\n",
    "            (4, \"Chapter 4: A Modern, Thriving Society\"),\n",
    "            (5, \"Chapter 5: The UK Government, the Law and Your Role\")\n",
    "        ]\n",
    "        \n",
    "        chapter_mapping = {}\n",
    "        for chapter_num, chapter_name in chapters_data:\n",
    "            cursor.execute(\n",
    "                \"INSERT IGNORE INTO chapters (chapter_number, name) VALUES (%s, %s)\",\n",
    "                (chapter_num, chapter_name)\n",
    "            )\n",
    "            cursor.execute(\n",
    "                \"SELECT id FROM chapters WHERE chapter_number = %s\", \n",
    "                (chapter_num,)\n",
    "            )\n",
    "            result = cursor.fetchone()\n",
    "            if result:\n",
    "                chapter_mapping[f\"chapter_{chapter_num}\"] = result[0]\n",
    "        \n",
    "        return chapter_mapping\n",
    "\n",
    "    def save_to_database(self):\n",
    "        \"\"\"Save collected data to MySQL database\"\"\"\n",
    "        if not self.db_config:\n",
    "            logger.error(\"Database configuration not provided\")\n",
    "            return\n",
    "        \n",
    "        connection = mysql.connector.connect(**self.db_config)\n",
    "        cursor = connection.cursor()\n",
    "        \n",
    "        try:\n",
    "            # Use the database\n",
    "            cursor.execute(\"USE uk_visa_test\")\n",
    "            \n",
    "            # Insert chapters\n",
    "            chapter_mapping = self._insert_chapters(cursor)\n",
    "            \n",
    "            # Insert tests and questions\n",
    "            test_mapping = {}\n",
    "            \n",
    "            for question in self.questions_data:\n",
    "                # Determine chapter_id\n",
    "                chapter_id = None\n",
    "                if question.chapter:\n",
    "                    chapter_id = chapter_mapping.get(question.chapter)\n",
    "                \n",
    "                # Create test key\n",
    "                test_key = f\"{question.test_type}_{question.test_number}_{question.chapter or 'none'}\"\n",
    "                \n",
    "                if test_key not in test_mapping:\n",
    "                    # Insert test\n",
    "                    cursor.execute(\n",
    "                        \"INSERT IGNORE INTO tests (chapter_id, test_number, test_type, url) VALUES (%s, %s, %s, %s)\",\n",
    "                        (chapter_id, question.test_number, question.test_type, f\"test-{question.test_number}\")\n",
    "                    )\n",
    "                    \n",
    "                    # Get test ID - handle NULL chapter_id properly\n",
    "                    if chapter_id is None:\n",
    "                        cursor.execute(\n",
    "                            \"SELECT id FROM tests WHERE chapter_id IS NULL AND test_number = %s AND test_type = %s\",\n",
    "                            (question.test_number, question.test_type)\n",
    "                        )\n",
    "                    else:\n",
    "                        cursor.execute(\n",
    "                            \"SELECT id FROM tests WHERE chapter_id = %s AND test_number = %s AND test_type = %s\",\n",
    "                            (chapter_id, question.test_number, question.test_type)\n",
    "                        )\n",
    "                    \n",
    "                    result = cursor.fetchone()\n",
    "                    if result:\n",
    "                        test_mapping[test_key] = result[0]\n",
    "                    else:\n",
    "                        # Fallback: get by test_number and type only\n",
    "                        cursor.execute(\n",
    "                            \"SELECT id FROM tests WHERE test_number = %s AND test_type = %s LIMIT 1\",\n",
    "                            (question.test_number, question.test_type)\n",
    "                        )\n",
    "                        result = cursor.fetchone()\n",
    "                        if result:\n",
    "                            test_mapping[test_key] = result[0]\n",
    "                \n",
    "                if test_key not in test_mapping:\n",
    "                    logger.warning(f\"Could not find or create test for {test_key}\")\n",
    "                    continue\n",
    "                \n",
    "                test_id = test_mapping[test_key]\n",
    "                \n",
    "                # Insert question\n",
    "                cursor.execute(\n",
    "                    \"INSERT INTO questions (test_id, question_id, question_text, question_type, explanation) VALUES (%s, %s, %s, %s, %s)\",\n",
    "                    (test_id, question.id, question.question_text, question.question_type, question.explanation)\n",
    "                )\n",
    "                \n",
    "                question_db_id = cursor.lastrowid\n",
    "                \n",
    "                # Insert answers\n",
    "                for answer in question.answers:\n",
    "                    cursor.execute(\n",
    "                        \"INSERT INTO answers (question_id, answer_id, answer_text, is_correct) VALUES (%s, %s, %s, %s)\",\n",
    "                        (question_db_id, answer.id, answer.text, answer.is_correct)\n",
    "                    )\n",
    "            \n",
    "            connection.commit()\n",
    "            logger.info(\"Data saved to database successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving to database: {e}\")\n",
    "            connection.rollback()\n",
    "            raise\n",
    "        finally:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "\n",
    "def main():\n",
    "    # Database configuration (update with your MySQL credentials)\n",
    "    db_config = {\n",
    "        'host': 'localhost',\n",
    "        'port': 3307,  # Default MySQL port\n",
    "        'user': 'root',\n",
    "        'password': '',\n",
    "        'database': 'uk_visa_test',\n",
    "        'charset': 'utf8mb4'\n",
    "    }\n",
    "    \n",
    "    # Initialize crawler\n",
    "    crawler = UKVisaTestCrawler(db_config)\n",
    "    \n",
    "    # Create database schema\n",
    "    crawler.create_database_schema()\n",
    "    \n",
    "    # Crawl all tests\n",
    "    crawler.crawl_all_tests()\n",
    "    \n",
    "    # Save to JSON file\n",
    "    crawler.save_to_json()\n",
    "    \n",
    "    # Save to database\n",
    "    crawler.save_to_database()\n",
    "    \n",
    "    print(f\"Crawling completed! Found {len(crawler.questions_data)} questions.\")\n",
    "    \n",
    "    # Print summary\n",
    "    chapter_questions = len([q for q in crawler.questions_data if q.test_type == \"chapter\"])\n",
    "    comprehensive_questions = len([q for q in crawler.questions_data if q.test_type == \"comprehensive\"])\n",
    "    \n",
    "    print(f\"Chapter-based questions: {chapter_questions}\")\n",
    "    print(f\"Comprehensive test questions: {comprehensive_questions}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vemv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
